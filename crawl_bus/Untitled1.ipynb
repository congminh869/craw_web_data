{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef6ff71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are you looking for? cat\n",
      "How many images do you want? 5\n",
      "Start searching...\n",
      "https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&q=cat\n",
      "found 0 images\n",
      "Start downloading...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "import requests # to sent GET requests\n",
    "from bs4 import BeautifulSoup # to parse HTML\n",
    "\n",
    "# user can input a topic and a number\n",
    "# download first n images from google image search\n",
    "\n",
    "GOOGLE_IMAGE = \\\n",
    "    'https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&'\n",
    "\n",
    "# The User-Agent request header contains a characteristic string \n",
    "# that allows the network protocol peers to identify the application type, \n",
    "# operating system, and software version of the requesting software user agent.\n",
    "# needed for google search\n",
    "usr_agent = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "    'Accept-Encoding': 'none',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "\n",
    "SAVE_FOLDER = 'images'\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(SAVE_FOLDER):\n",
    "        os.mkdir(SAVE_FOLDER)\n",
    "    download_images()\n",
    "    \n",
    "def download_images():\n",
    "    # ask for user input\n",
    "    data = input('What are you looking for? ')\n",
    "    n_images = int(input('How many images do you want? '))\n",
    "\n",
    "    print('Start searching...')\n",
    "    \n",
    "    # get url query string\n",
    "    searchurl = GOOGLE_IMAGE + 'q=' + data\n",
    "    print(searchurl)\n",
    "\n",
    "    # request url, without usr_agent the permission gets denied\n",
    "    response = requests.get(searchurl, headers=usr_agent)\n",
    "    html = response.text\n",
    "\n",
    "    # find all divs where class='rg_meta'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = soup.findAll('div', {'class': 'rg_meta'}, limit=n_images)\n",
    "    \n",
    "    # extract the link from the div tag\n",
    "    imagelinks= []\n",
    "    for re in results:\n",
    "        text = re.text # this is a valid json string\n",
    "        text_dict= json.loads(text) # deserialize json to a Python dict\n",
    "        link = text_dict['ou']\n",
    "        # image_type = text_dict['ity']\n",
    "        imagelinks.append(link)\n",
    "\n",
    "    print(f'found {len(imagelinks)} images')\n",
    "    print('Start downloading...')\n",
    "\n",
    "    for i, imagelink in enumerate(imagelinks):\n",
    "        # open image link and save as file\n",
    "        response = requests.get(imagelink)\n",
    "        \n",
    "        imagename = SAVE_FOLDER + '/' + data + str(i+1) + '.jpg'\n",
    "        with open(imagename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f289e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "driver = webdriver.Chrome('chromedriver_linux64/chromedriver')\n",
    "driver.get('https://www.google.com/')\n",
    "\n",
    "box = driver.find_element_by_xpath('/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "box.send_keys(\"bus viet nam\")\n",
    "box.send_keys(Keys.ENTER)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"hdtb-msb\"]/div[1]/div/div[2]/a').click()\n",
    "\n",
    "\n",
    "#Will keep scrolling down the webpage until it cannot scroll no more\n",
    "last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "    time.sleep(2)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    try:\n",
    "#         driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div[1]/div[2]/div[2]/input').click()\n",
    "        driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div/div[5]/input').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "    \n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div['+str(i)+']/a[1]/div[1]/img').screenshot('image/'+str(i)+'.jpg')\n",
    "    except:\n",
    "        pass\n",
    "    i = i + 1\n",
    "    if i == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af973d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "602f419c",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/craw/lib/python3.7/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m                                             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                             stdin=PIPE)\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/craw/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/craw/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1550\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Web Scraping course/chromedriver.exe': 'C:/Web Scraping course/chromedriver.exe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-df014c2d018e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C:/Web Scraping course/chromedriver.exe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.google.com/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/craw/lib/python3.7/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mservice_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             log_path=service_log_path)\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/craw/lib/python3.7/site-packages/selenium/webdriver/common/service.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 raise WebDriverException(\n\u001b[1;32m     82\u001b[0m                     \"'%s' executable needs to be in PATH. %s\" % (\n\u001b[0;32m---> 83\u001b[0;31m                         os.path.basename(self.path), self.start_error_message)\n\u001b[0m\u001b[1;32m     84\u001b[0m                 )\n\u001b[1;32m     85\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEACCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver.exe' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome('C:/Web Scraping course/chromedriver.exe')\n",
    "driver.get('https://www.google.com/')\n",
    "\n",
    "box = driver.find_element_by_xpath('//*[@id=\"tsf\"]/div[2]/div[1]/div[1]/div/div[2]/input')\n",
    "box.send_keys('giraffe')\n",
    "box.send_keys(Keys.ENTER)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"hdtb-msb-vis\"]/div[2]/a').click()\n",
    "\n",
    "\n",
    "#Will keep scrolling down the webpage until it cannot scroll no more\n",
    "last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "while True:\n",
    "    driver.execute_script('window.scrollTo(0,document.body.scrollHeight)')\n",
    "    time.sleep(2)\n",
    "    new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islmp\"]/div/div/div/div/div[5]/input').click()\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        pass\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "\n",
    "for i in range(1, 10):\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"islrg\"]/div[1]/div['+str(i)+']/a[1]/div[1]/img').screenshot('C:\\Web Scraping course\\Downloading every image\\giraffe ('+str(i)+').png')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97a21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
